    Hardware Engineering
AI voice assistants rely on a combination of local device hardware and powerful cloud infrastructure. Unlike gaming PCs, most commercial assistants run on low-power embedded processors, while heavy computation happens in remote servers.
Local Device Hardware
Devices such as Amazon Echo or Google Nest typically include:
ARM-based CPU Efficient, low-power processors designed for continuous listening.
Digital Signal Processors (DSPs)
Handle wake-word detection (“Hey Siri”, “Alexa”) without wasting any unnessery power.
Far-field Microphone Arrays
Multiple microphones with beamforming to capture voice accurately in noisy rooms, devices such as an amazon alexa or echo have these types of microphones 
They also have speakers so they could say the answer back to the user
They have Connectivity modules such as Wi-Fi or Bluetooth for communicating with cloud servers.
Voice assistance also rely on Cloud computing for them to complete most of their tasks, they use cloud computing to do their task to keep the main device small and compact without them having to use much power. These devices take Large Scale GPU proccess from computer in the compony to run whatever is needed. They distribute informations in matter of seconds with low letency, making it seem almost instint to the viewer askig the question. They also store anonymise voice logs to improve accuracy.

    Software Engineering
The use of Automatic Speech recognition such as "Ok Google", "Hey siri" , "Alexa". For example when the device hears one of these, it wakes the devices up from sleep mode, it then triggers a recording, and sends the subsequent audio to a cloud-based service. The servives then breaks the audio into segments, filters the background noise and then predicts what the next words will most likely be.
The use of Natural Language Processing goes beyond Speech recognition, NLP interputs meaning, context and intent, it adds another layer of understanding that reglar speech recognition doesn't have such as "Play Jazz" a normal speech recognition will look for something that has jazz in its name and might play a movie while NLP would hear the exact same sentence and decide to play Jazz music instead becuase it will be able to understand the meaning of the sentence.
The use of a Dialog Management allows the Ai voice assistant to keep track of the conversation while also allowing the speaker to keep asking questions freely without the assistant losing track of what the main point of the conversation is.
The use of machine learning, allows the assistant to expand their knowledge of understand, the different accents people may have, rememebering routines such as what time someone ask what the weather is everytime they wake up for example. The more people use these ai voice assistants the better they will get at answer questions faster and learning what kind of person they are.
The use of Intergrated API's allows the Assistant to connect to third party services such as smart home applicances, calanders and shopping lists or shopping carts for example smart bulbs, smart locks and amazon shopping chart.

    Ethical & User Experience Considerations
The privacy concerns people have about Voice Assistants is that they are always listening which means that if some hackers were able to connect into the assistant they would be able to listen along to the private converstation that the people could be having. The voice logs are also often stored to improve the accuracy of the Assistant however if someone is able to link multiple converstationt together they could be able to figure out who was speaking and then people would know what type of question these people have been asking. Many users also dont know what is stored and what is being used and not used with their information when they agree to the terms and agreement leaving many users feel unsafe with their information being spread. People are also scared because the assistants and embedded into many peoples lives, people feel like they are being surveilled all the time.











































#References
https://reolink.com/blog/how-does-alexa-work/?srsltid=AfmBOopIyBaNgvX2FjZEP1qDS01NO5DGoOZ9mh2BicMZDviXjl-tPGa9
https://www.embedded.com/how-extensive-signal-processing-chains-make-voice-assistants-just-work/?utm_source=chatgpt.com
https://developer.amazon.com/docs/device-specs/device-specifications-echo-show.html
https://developer.amazon.com/en-GB/alexa
https://milvus.io/ai-quick-reference/how-does-speech-recognition-work-in-smart-home-devices
https://developer.amazon.com/en-US/alexa/alexa-skills-kit/nlu
https://developer.amazon.com/en-US/alexa/alexa-skills-kit/dialog-management
https://bernardmarr.com/machine-learning-in-practice-how-does-amazons-alexa-really-work/




